{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cpaBJlszbG7O","outputId":"ab1c58ce-d0f5-4807-9c03-b0d5b4fd4768"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting OpenAI\n","  Downloading openai-1.44.0-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (9.0.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from OpenAI) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from OpenAI)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Collecting jiter<1,>=0.4.0 (from OpenAI)\n","  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (2.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from OpenAI) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (4.66.5)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->OpenAI) (3.8)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->OpenAI) (1.2.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->OpenAI) (2024.8.30)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->OpenAI)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->OpenAI)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->OpenAI) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->OpenAI) (2.20.1)\n","Downloading openai-1.44.0-py3-none-any.whl (367 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.8/367.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, OpenAI\n"]}],"source":["!pip install OpenAI tenacity"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":40245,"status":"ok","timestamp":1725758090060,"user":{"displayName":"Rakshitha Rao Ailneni","userId":"10554421985684110379"},"user_tz":300},"id":"J29M_NeBbKfs"},"outputs":[],"source":["import json\n","import os\n","import matplotlib.pyplot as plt\n","\n","def read_jsonl(path):\n","    examples = []\n","    with open(path, \"r\") as f:\n","        for line in f:\n","            line = line.strip()\n","            if line:\n","                try:\n","                    ex = json.loads(line)\n","                    examples.append(ex)\n","                except Exception as e:\n","                    print(e)\n","    return examples\n","\n","def get_image_from_problem(problem):\n","    img_folder='TRAINING'\n","    img_list=[]\n","    frame_list=[]\n","    reason_list=[]\n","    ids=[]\n","    for i in read_jsonl('predictions_whole/articulation-annotations.jsonl'):\n","        for j in i['articulations']:\n","            if problem in j['reasoning']:\n","                img_list.append(i['id'])\n","                frame_list.append(j['text'])\n","                reason_list.append(j['reasoning'])\n","                ids.append(i['id'])\n","    print(len(img_list))\n","    for x, f_name in enumerate(img_list):\n","      try:\n","        image_path = os.path.join(img_folder, f_name)\n","      except:\n","        print('Not found')\n","      image = plt.imread(image_path)\n","      print(frame_list[x])\n","      print(reason_list[x])\n","      plt.imshow(image)\n","      plt.title(frame_list[x])\n","      plt.xlabel(ids[x])\n","      #plt.axis('off')\n","      plt.show()\n","\n","def get_frame_from_problem(problem):\n","    img_folder='TRAINING'\n","    img_list=[]\n","    frame_list=[]\n","    reason_list=[]\n","    ids=[]\n","    for i in read_jsonl('predictions_whole/articulation-annotations.jsonl'):\n","        for j in i['articulations']:\n","            if problem in j['reasoning']:\n","                img_list.append(i['id'])\n","                frame_list.append(j['text'])\n","                reason_list.append(j['reasoning'])\n","                ids.append(i['id'])\n","    return frame_list, reason_list\n","\n","prblm_dict={}\n","reason_dict={}\n","with open('problems.txt', 'r') as f:\n","    problems = f.read().splitlines()\n","    problems=[problem.split(':')[0] for problem in problems]\n","for problem in problems:\n","    problem2='problem of '+ problem + ' arises'\n","    frame_list,reason_list=get_frame_from_problem(problem2)\n","    prblm_dict[problem]=frame_list\n","    reason_dict[problem]=reason_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vGppaglLbks6"},"outputs":[],"source":["#another method of calling openai\n","from openai import OpenAI, BadRequestError\n","from openai.types.chat import ChatCompletion\n","from tenacity import retry, stop_after_attempt, wait_random_exponential\n","import time\n","from typing import Optional\n","import json\n","import base64\n","\n","class MinimumDelay:\n","    def __init__(self, delay: float | int):\n","        self.delay = delay\n","        self.start = None\n","\n","    def __enter__(self):\n","        self.start = time.time()\n","\n","    def __exit__(self, exc_type, exc_val, exc_tb):\n","        end = time.time()\n","        seconds = end - self.start\n","        if self.delay > seconds:\n","            time.sleep(self.delay - seconds)\n","\n","@retry(wait=wait_random_exponential(min=1, max=90), stop=stop_after_attempt(3))\n","def chat(client: OpenAI, delay: float | int, **kwargs) -> ChatCompletion | None:\n","    try:\n","        with MinimumDelay(delay):\n","            return client.chat.completions.create(**kwargs)\n","    except BadRequestError as e:\n","        print(f\"Bad Request: {e}\")\n","        if \"safety\" in e.message:\n","            return None\n","        raise e\n","    except Exception as e:\n","        print(f\"Exception: {e}\")\n","        raise e\n","\n","def read_jsonl(path):\n","    with open(path, \"r\") as f:\n","        for line in f:\n","            line = line.strip()\n","            if line:\n","                ex = json.loads(line)\n","                yield ex\n","\n","def write_jsonl(path, data):\n","    with open(path, \"w\") as f:\n","        for i, ex in enumerate(data):\n","            try:\n","                f.write(json.dumps(ex) + \"\\n\")\n","            except TypeError as e:\n","                print(f\"Error writing element at index {i}: {ex}\")\n","                print(f\"TypeError: {e}\")\n","\n","# Function to encode the image\n","def encode_image(image_path):\n","    with open(image_path, \"rb\") as image_file:\n","        return base64.b64encode(image_file.read()).decode(\"utf-8\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CVxevGv0cBct"},"outputs":[],"source":["#define your api_key\n","client2 = OpenAI(api_key=api_key, timeout=60)\n","def handle_completion(client2, message, response_format, max_tokens=512, temperature=1.0, top_p=0.7, seed=0):\n","    chat_completion = client2.chat.completions.create(\n","    model=\"gpt-4o-2024-08-06\",\n","    messages=message,\n","    max_tokens=max_tokens,\n","    temperature=temperature,\n","    top_p=top_p,\n","    seed=seed,\n","    response_format=response_format\n","    )\n","\n","    extracted_data = chat_completion.choices[0].message.content\n","    return extracted_data\n","\n","def handle_completion2(client2, message, max_tokens=512, temperature=1.0, top_p=0.7, seed=0):\n","    chat_completion = client2.chat.completions.create(\n","    model=\"gpt-4o-2024-08-06\",\n","    messages=message,\n","    max_tokens=max_tokens,\n","    temperature=temperature,\n","    top_p=top_p,\n","    seed=seed,\n","    )\n","\n","    extracted_data = chat_completion.choices[0].message.content\n","    return extracted_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zBTgmrZbR8g5"},"outputs":[],"source":["problems_demo=[]\n","import pandas as pd\n","d=pd.read_excel('problems_demo_2.xlsx')\n","for i,row in d.iterrows():\n","    problems_demo.append({'problem':row['Problem'],'frame':row['Frame'],'rationale':row['Rationale'],'valid':row['valid'],'modified problem':row['modified problem'],'articulated':row['articulate'],'Comment':row['Comment']})\n","write_jsonl('problems_demo.jsonl',problems_demo)"]},{"cell_type":"markdown","metadata":{"id":"gxGPgE6UrOQf"},"source":["Trying out json schema: Articulated and validity. Should we modify or throw away invalid/improperly articulated frames."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pJjWwOECycQT"},"outputs":[],"source":["response_format = {\n","    \"type\": \"json_schema\",\n","    \"json_schema\": {\n","        \"name\": \"valid_find\",\n","        \"strict\": True,\n","        \"schema\": {\n","            \"type\": \"object\",\n","            \"properties\": {\n","                \"validity\": {\n","                    \"type\": \"string\",\n","                    \"enum\":[\"yes\",\"no\"]\n","                },\n","                \"modified_problem\": {\n","                    \"type\": \"string\",\n","\n","                },\n","                \"articulated\": {\n","                    \"type\": \"string\",\n","                    \"enum\":[\"yes\",\"no\"]\n","                }\n","            },\n","            \"required\": [\"validity\",\"modified_problem\",\"articulated\"],\n","            \"additionalProperties\": False\n","        }\n","    }\n","}\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kU-KFz-7rMVL"},"outputs":[],"source":["#consent\n","#alimony\n","comments={'both':'The problem is valid and properly articulated.','valid':'The problem is not valid.','art':'The problem is valid but not properly articulated.'}\n","#only check for problems other than obj, vio, ster, shaming, and other.\n","sys = '''You are an expert linguistic assistant.\n","Frames of communication select particular aspects of an issue and make them salient in communicating a message.\n","Frames of communication are ubiquitous in social media discourse and can impact how people understand issues and, more importantly, how they form their opinions.'''\n","changes=[]\n","\n","message=[{\"role\": \"system\", \"content\": sys},]\n","\n","demos=list(read_jsonl('problems_demo.jsonl'))\n","demos=demos[:10]\n","#take maximum 1 frames for each problem\n","\n","'''for i,d in enumerate(demos):\n","  #if i==0:\n","  user_p=f\"You will be given a frame and the problem associated with the frame. Assume you are a woman, is the problem correctly discovered and articulated with respect to the frame? If no, regenerate the problem.\"\n","  user_ps=f\"The problem is {d['problem']}. 1.a) The Frame associated with the problem is: {d['frame']}. 1.b) The rationale generated for the frame is: {d['rationale']}\"\n","  user_p=user_p+'\\n'+user_ps\n","  message.append({\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":user_p}]})\n","  if d['Comment']==comments['both']:\n","    message.append({\"role\":\"assistant\",\"content\":[{\"type\":\"json_schema\",\"json_schema\":{\"validity\": d['Comment']}}]})\n","  else:\n","    message.append({\"role\":\"assistant\",\"content\":[{\"type\":\"json_schema\",\"json_schema\":{\"validity\": d['Comment'], \"modified problem\": d[\"modified problem\"]}}]})\n","'''\n","for i,d in enumerate(demos):\n","  #if i==0:\n","  user_p=f\"You will be given a frame and the problem associated with the frame. From a woman's perspective, is the problem correctly discovered?. Is the problem articulated concisely with respect to the frame? Modify the problem only if the answer to any of these two questions is no. The modified problem should be specific and should not contain more than three words.\"\n","  user_ps=f\"The problem is {d['problem']}. 1.a) The Frame associated with the problem is: {d['frame']}. 1.b) The rationale generated for the frame is: {d['rationale']}\"\n","  user_p=user_p+'\\n'+user_ps\n","  message.append({\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":user_p}]})\n","  if d['Comment'] == comments['both']:\n","        validity_content = {\"validity\": d['valid'], 'articulated':d['articulated'], \"modified_problem\": \"\"}\n","  else:\n","        validity_content = {\"validity\": d['valid'],'articulated':d['articulated'], \"modified_problem\": d[\"modified problem\"]}\n","  message.append({\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": str(validity_content)}]})\n","message1=message.copy()\n","for problem in problems:\n","  if problem in ['objectification','violence','stereotyping','shaming','patriarchy','Other']:\n","    continue\n","  user_p=f\"You will be given a frame and the problem associated with the frame. From a woman's perspective, is the problem correctly discovered?. Is the problem articulated concisely with respect to the frame? Modify the problem only if the answer to any of these two questions is no. The modified problem should be specific and should not contain more than three words.\"\n","  user_ps=f\"The problem is {problem}. 1.a) The Frame associated with the problem is: {prblm_dict[problem][0]} 1.b) The rationale generated for the frame is: {reason_dict[problem][0]}\"\n","  user_p=user_p+'\\n'+user_ps\n","  message.append({\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":user_p}]})\n","  #print(message)\n","  response=handle_completion(client2, message,response_format)\n","  changes.append({'problem':problem, 'response':response})\n","  message=message1.copy()\n","  print(response)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zn3k33Hjhzwu"},"outputs":[],"source":["write_jsonl('valid_art_1.jsonl',changes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aIFGkM-OgqJE"},"outputs":[],"source":["\n","#assuming problem is present only in the beginning (the problem of - arises)\n","import re\n","changes=list(read_jsonl('valid_art_1.jsonl'))\n","\n","prblm_dict={}\n","reason_dict={}\n","with open('problems.txt', 'r') as f:\n","    problems = f.read().splitlines()\n","    problems=[problem.split(':')[0] for problem in problems]\n","for problem in problems:\n","    problem2='problem of '+ problem + ' arises'\n","    frame_list,reason_list=get_frame_from_problem(problem2)\n","    prblm_dict[problem]=frame_list\n","    reason_dict[problem]=reason_list\n","\n","\n","for change in changes:\n","  change['response']=json.loads(change['response'])\n","  modified_problem=change['response']['modified_problem']\n","\n","  if modified_problem=='':\n","    continue\n","  \n","  temp=reason_dict[change['problem']]\n","  ftemp=prblm_dict[change['problem']]\n","  del prblm_dict[change['problem']]\n","  del reason_dict[change['problem']]\n","\n","  mod_reasons=[]\n","  for reason in temp:\n","    #print(reason)\n","\n","    new_text = re.sub(change['problem'], modified_problem, reason, flags=re.IGNORECASE)\n","    mod_reasons.append(new_text)\n","    #print(new_text)\n","  if modified_problem in prblm_dict.keys():\n","    prblm_dict[modified_problem].extend(ftemp)\n","    reason_dict[modified_problem].extend(mod_reasons)\n","  else:\n","     prblm_dict[modified_problem]=ftemp\n","     reason_dict[modified_problem]=mod_reasons\n","\n","\n","  problems = [modified_problem if problem == change['problem'] else problem for problem in problems]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S-RkVIhMkXR0"},"outputs":[],"source":["\n","# Merging the dictionaries\n","merged_dict = {}\n","for problem in prblm_dict:\n","\n","\n","    frames = prblm_dict[problem]\n","    reasoning = reason_dict.get(problem, [])\n","\n","    # Pair frames and reasoning\n","    merged_list = [{\"frame\": frame, \"reasoning\": reason} for frame, reason in zip(frames, reasoning)]\n","\n","\n","    # Add to merged_dict\n","    merged_dict[problem] = merged_list\n","\n"]},{"cell_type":"markdown","metadata":{"id":"z3DbiTfOk7bG"},"source":["Paraphrases\n","\n","After finding valid and correctly articulated problems, modify them and find parapharses."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MhNmWsnbzBDv"},"outputs":[],"source":["#paraphrase module\n","\n","#A sentence can have multiple paraphrases. Choose the one with more frames.\n","\n","paraphrases=[]\n","sys = '''You are an expert linguistic assistant.\n","Frames of communication select particular aspects of an issue and make them salient in communicating a message.\n","Frames of communication are ubiquitous in social media discourse and can impact how people understand issues and, more importantly, how they form their opinions.'''\n","\n","\n","demos={'commodification': \"Paraphrases(commodification, reducing women's worth to their bodies, Objectification)\",'appearance-based discrimination':\"Paraphrases(appearance-based discrimination, appearance-based judgment, appearance-based derogation, appearance-based value)\", 'gender bias':\"Paraphrases(gender bias, gender inequality, gender superiority, gender hierarchy, resistance to gender equality)\"}\n","message=[{\"role\": \"system\", \"content\": sys},]\n","\n","for key, value in demos.items():\n","  user_p='''Here is a exhaustive list of problems extracted from the reasoning generated alongside frames: '''\n","  for i,p in enumerate(problems):\n","      user_p=user_p+str(i+1)+') '+p+' '\n","  user_p2='''For an input problem x, compare it to the other problems from the list and generate all the paraphrases in the format if they exist: Paraphrases(problem x, problem y, problem z, so on).'''\n","  user_p=user_p+'\\n'+user_p2\n","  user_ps=f\"The problem is {key}.\"\n","  user_p=user_p+'\\n'+user_ps\n","  message.append({\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":user_p}]})\n","  message.append({\"role\":\"assistant\",\"content\":[{\"type\":\"text\",\"text\":value}]})\n","\n","\n","\n","message1=message.copy()\n","for problem in problems:\n","  if problem in ['objectification','violence','stereotype','shaming','patriarchy','Other']:\n","    continue\n","  user_p='''Here is a exhaustive list of problems extracted from the reasoning generated alongside frames: '''\n","  for i,p in enumerate(problems):\n","    user_p=user_p+str(i+1)+') '+p+' '\n","  user_p2='''For an input problem x, compare it to the other problems from the list and generate all the paraphrases in the format if they exist: Paraphrases(problem x, problem y, problem z, so on).'''\n","  user_p=user_p+'\\n'+user_p2\n","  user_ps=f\"The problem is {problem}.\"\n","  user_p=user_p+'\\n'+ user_ps\n","  message.append({\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":user_p}]})\n","  response=handle_completion2(client2, message)\n","  #response = completion.choices[0].message.content\n","  paraphrases.append({'problem':problem, 'response':response})\n","  message=message1.copy()\n","  print(response)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1725601795378,"user":{"displayName":"Rakshitha Rao Ailneni","userId":"10554421985684110379"},"user_tz":300},"id":"JyXiv7hJpoTT","outputId":"a3872025-1202-4134-d514-c59b26104729"},"outputs":[{"name":"stdout","output_type":"stream","text":["500\n","479\n"]}],"source":["paraphrases=list(read_jsonl('pparaphrase_1.jsonl'))\n","print(len(paraphrases))\n","paraphrases_list=[]\n","for paraphrase in paraphrases:\n","\n","  if 'Paraphrases(' not in paraphrase['response']:\n","    continue\n","  pt=(paraphrase['response'].split('Paraphrases(')[1]).split(')')[0].split(', ')\n","  if len(pt)>1:\n","    paraphrases_list.append(tuple(pt))\n","print(len(paraphrases_list))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WVwagAf6HdqR"},"outputs":[],"source":["write_jsonl('pparaphrase_1.jsonl',paraphrases)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jxtQkQyhESv5"},"outputs":[],"source":["\n","# Function to merge paraphrased problems\n","def merge_paraphrased_problems(merged_dict, paraphrases):\n","\n","    for group in paraphrases:\n","\n","        existing_problems = [p for p in group if p in merged_dict]\n","        if  len(existing_problems)==0:\n","            continue\n","        #what if len==1.\n","\n","        main_problem = max(existing_problems, key=lambda p: len(merged_dict[p]))\n","\n","        # Collect all frames and reasoning from the other existing problems\n","        for problem in existing_problems:\n","            if problem != main_problem:\n","                merged_dict[main_problem].extend(merged_dict[problem])\n","                del merged_dict[problem]  # Remove the merged problem\n","\n","        #Optional: remove duplicates from the merged list\n","        seen = set()\n","        merged_dict[main_problem] = [\n","            d for d in merged_dict[main_problem]\n","            if (d['frame'], d['reasoning']) not in seen and not seen.add((d['frame'], d['reasoning']))\n","        ]\n","\n","    return merged_dict\n","\n","# Apply the function\n","updated_merged_dict = merge_paraphrased_problems(merged_dict, paraphrases_list)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20457,"status":"ok","timestamp":1725601816002,"user":{"displayName":"Rakshitha Rao Ailneni","userId":"10554421985684110379"},"user_tz":300},"id":"4BextpkQLTj3","outputId":"b10bb1ca-4919-459d-9c27-dfe4423562b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of keys with missing frame_id: 0\n"]}],"source":["frame_file = 'predictions_whole/articulations-unique.jsonl'\n","total_files = list(read_jsonl(frame_file))\n","frames = [j['text'] for j in total_files]\n","\n","# Iterate through frames and problems in the dictionary\n","for i, frame in enumerate(frames):\n","    for key, value in updated_merged_dict.items():\n","        for j, v in enumerate(value):\n","            if v['frame'] == frame:\n","                updated_merged_dict[key][j]['frame_id'] = i + 1\n","missing_frame_id_count = 0\n","\n","for key, value in updated_merged_dict.items():\n","    if any('frame_id' not in v for v in value):\n","        missing_frame_id_count += 1\n","\n","print(f\"Number of keys with missing frame_id: {missing_frame_id_count}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HgNx42NmZ9-b"},"outputs":[],"source":["with open('problems_final.txt', 'w') as f:\n","    for p in updated_merged_dict.keys():\n","      f.write(p+'\\n')\n"]},{"cell_type":"markdown","metadata":{"id":"24E4hXcjSWsi"},"source":["Sub problems"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PEO8WeSa0yzK"},"outputs":[],"source":["#change demos based on updated problems\n","#skip the root problems\n","\n","subproblems=[]\n","sys = '''You are an expert linguistic assistant.\n","Frames of communication select particular aspects of an issue and make them salient in communicating a message.\n","Frames of communication are ubiquitous in social media discourse and can impact how people understand issues and, more importantly, how they form their opinions.'''\n","\n","demos={'sexual harassment': \"subproblem(Sexual harassment, Violence)\", 'dehumanization': \"subproblem(dehumanization, Objectification)\", \"ageism\": \"subproblem(ageism, Stereotype)\", \"trivializing women's issues\":\"subproblem(trivializing, trivializing women's issues)\",}\n","message=[{\"role\": \"system\", \"content\": sys},]\n","\n","for key, value in demos.items():\n","  user_p='''Here is a exhaustive list of problems extracted from the reasoning generated alongside frames: '''\n","  for i,p in enumerate(problems):\n","    user_p=user_p+str(i+1)+') '+p+' '\n","  user_p2='''For an input problem x, compare it to the other problems from the list and find out it's closest parent problem (if it exists). The output should be in the format: subproblem(problem x, problem y).'''\n","  user_p=user_p+'\\n'+user_p2\n","  user_ps=f\"The problem is {key}.\"\n","  user_p=user_p+'\\n'+user_ps\n","  message.append({\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":user_p}]})\n","  message.append({\"role\":\"assistant\",\"content\":[{\"type\":\"text\",\"text\":value}]})\n","\n","message1=message.copy()\n","cnt=0\n","for problem in problems:\n","  if problem in ['objectification','violence','stereotyping','shaming','patriarchy','Other']:\n","    continue\n","  user_p='''Here is a exhaustive list of problems extracted from the reasoning generated alongside frames: '''\n","  for i,p in enumerate(problems):\n","    user_p=user_p+str(i+1)+') '+p+' '\n","  user_p2='''For an input problem x, compare it to the other problems from the list and find out it's closest parent problem (if it exists). The output should be in the format: subproblem(problem x, problem y).'''\n","  user_p=user_p+'\\n'+user_p2\n","  user_ps=f\"The problem is {problem}.\"\n","  user_p=user_p+'\\n'+ user_ps\n","  message.append({\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":user_p}]})\n","  response=handle_completion2(client2, message)\n","  subproblems.append({'problem':problem, 'response':response})\n","  message=message1.copy()\n","  print(response)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JNBfNRanZxms"},"outputs":[],"source":["write_jsonl('subproblems_1.jsonl',subproblems)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3fUhuHE8KCVV"},"outputs":[],"source":["import json\n","from collections import defaultdict\n","\n","# Function to read frames multiple and convert it into key plus list of frmes.\n","def read_from_jsonl_ind(filename):\n","    data = defaultdict(list)\n","\n","    with open(filename, 'r') as file:\n","        for line in file:\n","            record = json.loads(line.strip())\n","            problem = record.pop(\"problem\")\n","            data[problem].append(record)\n","\n","    # Convert defaultdict back to a regular dict\n","    return dict(data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":422,"status":"ok","timestamp":1725310148331,"user":{"displayName":"Rakshitha Rao Ailneni","userId":"10554421985684110379"},"user_tz":300},"id":"tY232euBeSd1","outputId":"5f4a7a35-b916-4501-beb6-30e452785dfb"},"outputs":[{"name":"stdout","output_type":"stream","text":["103\n"]}],"source":["subproblems=list(read_jsonl('subproblems_1c.jsonl'))\n","\n","subproblems_list=[]\n","for subproblem in subproblems:\n","\n","  if 'subproblem(' not in subproblem['response']:\n","    continue\n","  pt=(subproblem['response'].split('subproblem(')[1]).split(')')[0].split(', ')\n","  if len(pt)>1:\n","    subproblems_list.append(tuple(pt))\n","print(len(subproblems_list))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":165,"status":"ok","timestamp":1725310152272,"user":{"displayName":"Rakshitha Rao Ailneni","userId":"10554421985684110379"},"user_tz":300},"id":"Hd7ZGeuJgkv5","outputId":"1cda8442-8476-48e9-d927-90dfb97bdb84"},"outputs":[{"name":"stdout","output_type":"stream","text":["patriarchy\n","  enforced gender norms\n","    gender essentialism\n","    constrained gender identity\n","  double standards\n","    conditional respect\n","  undermining women's capabilities\n","    demeaning aspirations\n","  male validation\n","  gender superiority\n","  toxic masculinity\n","  dismissing women's rights\n","    undermining advocacy\n","      undermining women's rights movements\n","  historical misogyny\n","  subjugation\n","  patriarchal control\n","    mistrust\n","      deception\n","      conspiracy thinking\n","      betrayal\n","        infidelity\n","      commitment phobia\n","    possessiveness\n","    gatekeeping\n","    coercion\n","    ownership\n","    policing women's bodies\n","    forced marriage\n","objectification\n","  sexualization\n","    unrealistic beauty standards\n","    sexual innuendo usage\n","    sexual entitlement\n","    age-related sexualization\n","  dehumanization\n","    intellectual degradation\n","    disposability\n","    demonization\n","      fearmongering\n","  ranking women\n","discrimination\n","  ableism\n","  transphobia\n","  exclusion\n","  workplace discrimination\n","    professional misconduct\n","  homophobia\n","  intersectional prejudice\n","    racism\n","stereotyping\n","  judgement\n","    false accusations\n","  appearance-based discrimination\n","  misrepresentation\n","    false equivalence\n","    misunderstanding feminism\n","    pseudoscience\n","  cultural insensitivity\n","  single motherhood stigmatization\n","  reductionism\n","  ageism\n","violence\n","  promoting rape culture\n","    victim blaming\n","    sexual harassment\n","      trivializing consent\n","    endorsing marital rape\n","    necrophilia\n","  incest\n","  promoting self-harm\n","  control and abuse\n","trivializing serious issues\n","  trivializing women's issues\n","    trivializing feminism\n","      minimizing feminist efforts\n","    trivializing women's sexual satisfaction\n","  trivializing gender equality\n","  trivializing sexual assault\n","  trivializing mental health\n","  trivializing oppression\n","  trivializing infidelity\n","  trivializing prostitution\n","  reverse sexism\n","  trivializing eating disorders\n","  trivializing trauma\n","  trivializing addiction\n","  trivializing representation\n","shaming\n","  disrespect\n","    dismissiveness\n","      denial\n","        deflection\n","        scapegoating\n","          divisiveness\n","      invalidating women's experiences\n","    derogatory labeling\n","    ridicule\n","    disrespecting sex workers\n","    disrespecting sex workers\n","  fat shaming\n","  stigmatization\n","    menstruation stigma\n","exploitation\n","  transactional relationships\n","  materialism\n","  pedophilia\n","  lack of accountability\n"]}],"source":["from collections import defaultdict\n","problems=list(updated_merged_dict.keys())\n","hierarchical_graph = defaultdict(list)\n","\n","for child, parent in subproblems_list:\n","    hierarchical_graph[parent].append(child)\n","\n","# Dictionaries to store the relationships\n","parent_to_children = defaultdict(list)\n","child_to_parent = {}\n","\n","# Build the graph relationships\n","for child, parent in subproblems_list:\n","    parent_to_children[parent].append(child)\n","    child_to_parent[child] = parent\n","\n","# Optional: Add isolated problems without parents (nodes with no incoming edges)\n","for problem in problems:\n","    if problem not in hierarchical_graph and problem not in [child for child, parent in subproblems_list]:\n","        hierarchical_graph[problem] = []\n","\n","# Function to recursively print the hierarchy\n","def print_hierarchy(graph, parent, level=0):\n","    print(\"  \" * level + parent)\n","    for child in graph[parent]:\n","        print_hierarchy(graph, child, level + 1)\n","\n","# Find root nodes (problems that have no parents)\n","roots = [problem for problem in hierarchical_graph if problem not in [child for child, parent in subproblems_list]]\n","\n","# Print the hierarchical graph\n","for root in roots:\n","    print_hierarchy(hierarchical_graph, root)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOclvLWljEnOJWQH7SSVXsx","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
