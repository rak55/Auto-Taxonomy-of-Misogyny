{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":569,"status":"ok","timestamp":1726159378256,"user":{"displayName":"Rakshitha Rao Ailneni","userId":"10554421985684110379"},"user_tz":300},"id":"ytoVO1w2guAq"},"outputs":[],"source":["import json\n","import os\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import heapq\n","from tqdm import tqdm\n","\n","def read_jsonl(path):\n","    examples = []\n","    with open(path, \"r\") as f:\n","        for line in f:\n","            line = line.strip()\n","            if line:\n","                try:\n","                    ex = json.loads(line)\n","                    examples.append(ex)\n","                except Exception as e:\n","                    print(e)\n","    return examples\n","\n","def get_image_from_problem(problem):\n","    img_folder='TRAINING'\n","    img_list=[]\n","    frame_list=[]\n","    reason_list=[]\n","    ids=[]\n","    for i in read_jsonl('predictions_whole/articulation-annotations.jsonl'):\n","        for j in i['articulations']:\n","            if problem in j['reasoning']:\n","                img_list.append(i['id'])\n","                frame_list.append(j['text'])\n","                reason_list.append(j['reasoning'])\n","                ids.append(i['id'])\n","    print(len(img_list))\n","    for x, f_name in enumerate(img_list):\n","      try:\n","        image_path = os.path.join(img_folder, f_name)\n","      except:\n","        print('Not found')\n","      image = plt.imread(image_path)\n","      print(frame_list[x])\n","      print(reason_list[x])\n","      plt.imshow(image)\n","      plt.title(frame_list[x])\n","      plt.xlabel(ids[x])\n","      #plt.axis('off')\n","      plt.show()\n","\n","def get_frame_from_problem(problem):\n","    img_folder='TRAINING'\n","    img_list=[]\n","    frame_list=[]\n","    reason_list=[]\n","    ids=[]\n","    for i in read_jsonl('predictions_whole/articulation-annotations.jsonl'):\n","        for j in i['articulations']:\n","            if problem in j['reasoning']:\n","                img_list.append(i['id'])\n","                frame_list.append(j['text'])\n","                reason_list.append(j['reasoning'])\n","                ids.append(i['id'])\n","    return frame_list, reason_list"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":132,"status":"ok","timestamp":1726159383159,"user":{"displayName":"Rakshitha Rao Ailneni","userId":"10554421985684110379"},"user_tz":300},"id":"KTiFBP3igyK3"},"outputs":[],"source":["import time\n","from typing import Optional\n","import json\n","import base64\n","from collections import defaultdict\n","\n","\n","def read_jsonl(path):\n","    with open(path, \"r\") as f:\n","        for line in f:\n","            line = line.strip()\n","            if line:\n","                ex = json.loads(line)\n","                yield ex\n","\n","def write_jsonl(path, data):\n","    with open(path, \"w\") as f:\n","        for i, ex in enumerate(data):\n","            try:\n","                f.write(json.dumps(ex) + \"\\n\")\n","            except TypeError as e:\n","                print(f\"Error writing element at index {i}: {ex}\")\n","                print(f\"TypeError: {e}\")\n","\n","# Function to encode the image\n","def encode_image(image_path):\n","    with open(image_path, \"rb\") as image_file:\n","        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n","\n","def write_to_jsonl(data, filename):\n","    with open(filename, 'w') as file:\n","        for key, value in data.items():\n","            for entry in value:\n","                record = {\"problem\": key}\n","                record.update(entry)\n","                file.write(json.dumps(record) + \"\\n\")\n","\n","def read_from_jsonl_ind(filename):\n","    data = defaultdict(list)\n","\n","    with open(filename, 'r') as file:\n","        for line in file:\n","            record = json.loads(line.strip())\n","            problem = record.pop(\"problem\")\n","            data[problem].append(record)\n","\n","    # Convert defaultdict back to a regular dict\n","    return dict(data)"]},{"cell_type":"markdown","metadata":{"id":"F65nmRAHh8_-"},"source":["start of relations"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1216,"status":"ok","timestamp":1726159388039,"user":{"displayName":"Rakshitha Rao Ailneni","userId":"10554421985684110379"},"user_tz":300},"id":"uXShuu71h8Ob"},"outputs":[],"source":["updated_merged_dict=read_from_jsonl_ind('updated_merged_dict_final.jsonl')\n","subproblems=list(read_jsonl('subproblems_1c.jsonl'))\n","\n","subproblems_list=[]\n","for subproblem in subproblems:\n","\n","  if 'subproblem(' not in subproblem['response']:\n","    continue\n","  pt=(subproblem['response'].split('subproblem(')[1]).split(')')[0].split(', ')\n","  if len(pt)>1:\n","    subproblems_list.append(tuple(pt))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vz25Z2DD68kB"},"outputs":[],"source":["import random\n","\n","def write_frame_examples(updated_dict, num_examples_per_problem, output_file):\n","    with open(output_file, 'w') as file:\n","        for problem, frame_list in updated_dict.items():\n","            # Print problem statement\n","            file.write(f\"Problem: {problem}\\n\")\n","\n","            # Select a random sample of frames, or use all frames if fewer than the requested number\n","            selected_frames = random.sample(frame_list, min(len(frame_list), num_examples_per_problem))\n","\n","            for frame in selected_frames:\n","                file.write(f\"  Frame ID: {frame['frame_id']}\\n\")\n","                file.write(f\"  Frame: {frame['frame']}\\n\")\n","                file.write(f\"  Reasoning: {frame['reasoning']}\\n\\n\")\n","\n","            file.write(\"\\n\")  # Add extra line for readability\n","def find_problem_by_frame(problem_dict, target_frame):\n","    for problem, details in problem_dict.items():\n","      for x in details:\n","        if x[\"frame\"] == target_frame:\n","          return problem, x\n","\n","    return None\n","write_frame_examples(updated_merged_dict,5,'problem_frame_ex.txt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":160,"status":"ok","timestamp":1725985748801,"user":{"displayName":"Rakshitha Rao Ailneni","userId":"10554421985684110379"},"user_tz":300},"id":"eOeSTM6yiCFs","outputId":"f6a3ec72-192d-4753-f974-0e98455f384d"},"outputs":[{"name":"stdout","output_type":"stream","text":["patriarchal attitudes\n","  enforced gender norms\n","    double standards\n","    gender essentialism\n","  promoting infidelity\n","  undermining women's capabilities\n","  wage disparity\n","  male validation\n","  intellectual degradation\n","  incest\n","  conditional respect\n","  toxic masculinity\n","  dismissing women's rights\n","    undermining women's rights movements\n","  women subjugation\n","  demeaning aspirations\n","  patriarchal control\n","    possessiveness\n","    gatekeeping\n","    coercion\n","    ownership\n","    policing women's bodies\n","    forced marriage\n","objectification\n","  sexualization\n","    sexual innuendo\n","    sexual entitlement\n","    age-related sexualization\n","  unrealistic beauty standards\n","discrimination of women\n","  ableism\n","  transphobia\n","  neo sexism\n","  appearance-based discrimination\n","  classism\n","  exclusion\n","  workplace discrimination\n","  racism\n","  homophobia\n","  ageism\n","  reverse sexism\n","  constrained gender identity\n","  intersectional prejudice\n","disrespect towards women\n","  dismissiveness\n","    invalidating women's experiences\n","  cultural insensitivity\n","  disrespecting sex workers\n","  lack of accountability by men\n","  stigmatization\n","    menstruation stigma\n","    single motherhood stigmatization\n","stereotyping\n","  biased judgement\n","    false accusations\n","    divisiveness\n","    scapegoating\n","  misrepresentation\n","    deflection\n","    false equivalence\n","    misunderstanding feminism\n","  mistrust\n","    commitment phobia\n","  reductionism\n","shaming\n","  derogatory labeling\n","  ridicule\n","  fat shaming\n","trivializing serious issues\n","  trivializing women's issues\n","    trivializing sexual assault\n","    minimizing feminist efforts\n","    trivializing women's sexual satisfaction\n","  trivializing mental health issues\n","  trivializing oppression\n","  trivializing infidelity\n","  trivializing prostitution\n","  trivializing eating disorders\n","  trivializing addiction\n","  trivializing the need for representation\n","violence\n","  sexual harassment\n","    victim blaming\n","    promoting rape culture\n","    trivializing consent\n","    endorsing marital rape\n","    endorsing necrophilia\n","  promoting self-harm\n","  professional misconduct\n","exploitation of women by men\n","  transactional relationships\n","  pedophilia exploitation\n","pseudoscience\n","  conspiracy thinking\n","dehumanization of women\n","  disposability\n","  demonization\n","  fearmongering\n","  women valuation\n","\n"]}],"source":["from collections import defaultdict\n","problems=list(updated_merged_dict.keys())\n","hierarchical_graph = defaultdict(list)\n","\n","for child, parent in subproblems_list:\n","    hierarchical_graph[parent].append(child)\n","\n","# Dictionaries to store the relationships\n","parent_to_children = defaultdict(list)\n","child_to_parent = {}\n","\n","# Build the graph relationships\n","for child, parent in subproblems_list:\n","    parent_to_children[parent].append(child)\n","    child_to_parent[child] = parent\n","\n","# Optional: Add isolated problems without parents (nodes with no incoming edges)\n","for problem in problems:\n","    if problem not in hierarchical_graph and problem not in [child for child, parent in subproblems_list]:\n","        hierarchical_graph[problem] = []\n","\n","# Function to recursively print the hierarchy\n","def print_hierarchy(graph, parent, level=0):\n","    print(\"  \" * level + parent)\n","    for child in graph[parent]:\n","        print_hierarchy(graph, child, level + 1)\n","\n","# Find root nodes (problems that have no parents)\n","roots = [problem for problem in hierarchical_graph if problem not in [child for child, parent in subproblems_list]]\n","\n","# Print the hierarchical graph\n","for root in roots:\n","    print_hierarchy(hierarchical_graph, root)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153,"status":"ok","timestamp":1725646351634,"user":{"displayName":"Rakshitha Rao Ailneni","userId":"10554421985684110379"},"user_tz":300},"id":"SiwfbCUAta4S","outputId":"4251e822-afed-43ec-9909-d22c04bc847a"},"outputs":[],"source":["def find_problem_by_frame(problem_dict, target_frame):\n","    for problem, details in problem_dict.items():\n","      for x in details:\n","        if x[\"frame\"] == target_frame:\n","          return problem, x\n","\n","    return None\n","\n","def print_hierarchy_frame_count(child_to_parent, parent_to_child, updated_merged_dict):\n","    # Step 1: Find roots (nodes with no parents)\n","    all_nodes = set(parent_to_child.keys()).union(set(child_to_parent.keys()))\n","    roots = [node for node in all_nodes if node not in child_to_parent]\n","\n","    # Step 2: Depth-First Search (DFS) to traverse hierarchy in order\n","    def dfs(node, level=0):\n","        # Get the number of frames from updated_merged_dict\n","        num_frames = len(updated_merged_dict.get(node, []))\n","        print(f\"{' ' * level * 2}Key: {node}, Number of frames: {num_frames}\")\n","\n","        # Recursively visit each child in the hierarchy\n","        for child in parent_to_child.get(node, []):\n","            dfs(child, level + 1)\n","\n","    # Step 3: Traverse from each root in hierarchical order\n","    for root in roots:\n","        dfs(root)\n","# Example usage\n","print_hierarchy_frame_count(child_to_parent, parent_to_children,updated_merged_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gjsc-umUxft-"},"outputs":[],"source":["def get_image_from_problem(problem):\n","    img_folder='TRAINING'\n","    img_list=[]\n","    frame_list=[]\n","    reason_list=[]\n","    ids=[]\n","    for i in read_jsonl('predictions_whole/articulation-annotations.jsonl'):\n","        for j in i['articulations']:\n","            if problem in j['reasoning']:\n","                img_list.append(i['id'])\n","                frame_list.append(j['text'])\n","                reason_list.append(j['reasoning'])\n","                ids.append(i['id'])\n","    print(len(img_list))\n","    for x, f_name in enumerate(img_list):\n","      try:\n","        image_path = os.path.join(img_folder, f_name)\n","      except:\n","        print('Not found')\n","      image = plt.imread(image_path)\n","      print(frame_list[x])\n","      print(reason_list[x])\n","      plt.imshow(image)\n","      plt.title(frame_list[x])\n","      plt.xlabel(ids[x])\n","      #plt.axis('off')\n","      plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aJghWguQ3RS9"},"outputs":[],"source":["def get_frames(img_id):\n","  for i in read_jsonl('predictions_whole/articulation-annotations.jsonl'):\n","    if i['id']==img_id:\n","      return i['articulations']\n","def get_frames2(frame):\n","  for i in read_jsonl('predictions_whole/articulation-annotations.jsonl'):\n","    for j in i['articulations']:\n","      if j['text']==frame:\n","        return i['id']"]},{"cell_type":"markdown","metadata":{"id":"jKHAlCwMCGAa"},"source":["Evaluation"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":170,"status":"ok","timestamp":1726159410619,"user":{"displayName":"Rakshitha Rao Ailneni","userId":"10554421985684110379"},"user_tz":300},"id":"caZNSzJizU0z"},"outputs":[],"source":["from itertools import combinations\n","\n","def get_parent_pairs(subproblem_parent_pairs):\n","    \"\"\"Returns a dictionary where keys are subproblems and values are their parents.\"\"\"\n","    parent_dict = {}\n","    for subproblem, parent in subproblem_parent_pairs:\n","        parent_dict[subproblem] = parent\n","    return parent_dict\n","\n","def get_subproblem_pairs(parent_dict):\n","    \"\"\"Generate all possible pairs of subproblems and check if they have the same parent.\"\"\"\n","    pairs = set()\n","    subproblems = list(parent_dict.keys())\n","\n","    for sp1, sp2 in combinations(subproblems, 2):\n","        if parent_dict[sp1] == parent_dict[sp2]:\n","            pairs.add((sp1, sp2))\n","\n","    return pairs\n","\n","def calculate_rand_index_for_subproblems(pred_pairs, gold_pairs, all_subproblems):\n","    # Step 1: Generate all possible pairs of subproblems\n","    all_pairs = set(combinations(sorted(all_subproblems), 2))\n","\n","    # Step 2: Calculate counts for n11, n00, n10, n01\n","    n11 = len(pred_pairs & gold_pairs)  # In the same cluster in both\n","    n00 = len(all_pairs - (pred_pairs | gold_pairs))  # In different clusters in both\n","    n10 = len(pred_pairs - gold_pairs)  # In the same cluster in predicted, different in gold\n","    n01 = len(gold_pairs - pred_pairs)  # In the same cluster in gold, different in predicted\n","\n","    # Step 3: Calculate Rand Index\n","    rand_index = (n11 + n00) / (n11 + n10 + n01 + n00) if (n11 + n10 + n01 + n00) > 0 else 0\n","    return rand_index\n","\n","\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":542,"status":"ok","timestamp":1726159413950,"user":{"displayName":"Rakshitha Rao Ailneni","userId":"10554421985684110379"},"user_tz":300},"id":"7dC522tVzWWq","outputId":"d762ed42-6ea1-4b5f-b29a-4522118fe56f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Rand Index for (subproblem, parent) pairs: 0.9625\n"]}],"source":["pred_subproblem=list(read_jsonl('subproblems_1cb.jsonl'))\n","gold_subproblem=list(read_jsonl('subproblems_1c.jsonl'))\n","\n","gold_subproblems_list=[]\n","for subproblem in gold_subproblem:\n","\n","  if 'subproblem(' not in subproblem['response']:\n","    continue\n","  pt=(subproblem['response'].split('subproblem(')[1]).split(')')[0].split(', ')\n","  if len(pt)>1:\n","    gold_subproblems_list.append(tuple(pt))\n","\n","pred_subproblems_list=[]\n","for subproblem in pred_subproblem:\n","\n","  if 'subproblem(' not in subproblem['response']:\n","    continue\n","  pt=(subproblem['response'].split('subproblem(')[1]).split(')')[0].split(', ')\n","  if len(pt)>1:\n","    pred_subproblems_list.append(tuple(pt))\n","\n","pred_parent_dict = get_parent_pairs(pred_subproblems_list)\n","gold_parent_dict = get_parent_pairs(gold_subproblems_list)\n","\n","# Step 2: Generate subproblem pairs (same parent) for both predicted and gold\n","pred_pairs = get_subproblem_pairs(pred_parent_dict)\n","gold_pairs = get_subproblem_pairs(gold_parent_dict)\n","\n","# Step 3: Get all subproblems from both taxonomies\n","all_subproblems = set(pred_parent_dict.keys()).union(gold_parent_dict.keys())\n","\n","# Step 4: Calculate Rand Index\n","rand_index = calculate_rand_index_for_subproblems(pred_pairs, gold_pairs, all_subproblems)\n","print(f\"Rand Index for (subproblem, parent) pairs: {rand_index:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F459JS9_xZ6D"},"outputs":[],"source":["from collections import defaultdict\n","\n","def compute_ancestral_pairs(pairs):\n","    ancestors = defaultdict(set)\n","\n","    # Add direct parent relationships\n","    for child, parent in pairs:\n","        ancestors[child].add(parent)\n","\n","    # Add indirect ancestors (transitive closure)\n","    for child in ancestors:\n","        to_process = list(ancestors[child])\n","        while to_process:\n","            ancestor = to_process.pop()\n","            if ancestor in ancestors:\n","                for grandparent in ancestors[ancestor]:\n","                    if grandparent not in ancestors[child]:\n","                        ancestors[child].add(grandparent)\n","                        to_process.append(grandparent)\n","    return ancestors\n","\n","def compute_ancestor_f1(gold_pairs, predicted_pairs):\n","    gold_ancestors = compute_ancestral_pairs(gold_pairs)\n","    predicted_ancestors = compute_ancestral_pairs(predicted_pairs)\n","\n","    # Calculate true positives\n","    tp = 0\n","    total_predicted = 0\n","    total_gold = 0\n","\n","    # Count the number of correct (is-a) pairs\n","    for child, ancestors in predicted_ancestors.items():\n","        total_predicted += len(ancestors)\n","        if child in gold_ancestors:\n","            tp += len(ancestors & gold_ancestors[child])\n","\n","    for child, ancestors in gold_ancestors.items():\n","        total_gold += len(ancestors)\n","\n","    # Precision, Recall, F1\n","    precision = tp / total_predicted if total_predicted > 0 else 0\n","    recall = tp / total_gold if total_gold > 0 else 0\n","    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","\n","    return precision, recall, f1\n","\n","# Example usage\n","gold_standard = [(\"subproblem1\", \"parent1\"), (\"subproblem2\", \"parent1\"), (\"subproblem3\", \"parent2\")]\n","predicted_taxonomy = [(\"subproblem1\", \"parent1\"), (\"subproblem2\", \"parent2\"), (\"subproblem3\", \"parent1\")]\n","\n","Pa, Ra, F1a = compute_ancestor_f1(gold_standard, predicted_taxonomy)\n","\n","print(f\"Ancestor Precision: {Pa:.2f}, Ancestor Recall: {Ra:.2f}, Ancestor F1: {F1a:.2f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EXqXRQ68Cwbr"},"outputs":[],"source":["def compute_edge_f1(gold_pairs, predicted_pairs):\n","    gold_set = set(gold_pairs)\n","    predicted_set = set(predicted_pairs)\n","\n","    # True Positives (correct predicted edges)\n","    tp = len(gold_set & predicted_set)\n","\n","    # Total predicted and total gold edges\n","    total_predicted = len(predicted_set)\n","    total_gold = len(gold_set)\n","\n","    # Precision, Recall, F1\n","    precision = tp / total_predicted if total_predicted > 0 else 0\n","    recall = tp / total_gold if total_gold > 0 else 0\n","    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","\n","    return precision, recall, f1\n","\n","# Example usage\n","gold_standard = [(\"subproblem1\", \"parent1\"), (\"subproblem2\", \"parent1\"), (\"subproblem3\", \"parent2\")]\n","predicted_taxonomy = [(\"subproblem1\", \"parent1\"), (\"subproblem2\", \"parent2\"), (\"subproblem3\", \"parent1\")]\n","\n","Pe, Re, F1e = compute_edge_f1(gold_standard, predicted_taxonomy)\n","\n","print(f\"Edge Precision: {Pe:.2f}, Edge Recall: {Re:.2f}, Edge F1: {F1e:.2f}\")\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN4arxf0CRNXqUsgoDKmyYr","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
